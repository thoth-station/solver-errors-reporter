{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029492,
     "end_time": "2020-08-14T21:58:32.096707",
     "exception": false,
     "start_time": "2020-08-14T21:58:32.067215",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cluster errors to identify the type of errors that can appear in solver reports "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026152,
     "end_time": "2020-08-14T21:58:32.151564",
     "exception": false,
     "start_time": "2020-08-14T21:58:32.125412",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Import Packages](#Import_packages)\n",
    "3. [Load the clean solver data saved by 'PreprocessSolverErrorData' notebook](#load_clean_data)\n",
    "4. [Filter data using Solver / datetime](#filter)\n",
    "5. [Word to Vector Conversion using Continuous Bag of Words model (CBOW)](#word2vec)\n",
    "6. [Sentence (error message) to vector conversion](#sent2vec)\n",
    "7. [Clustering using DBScan](#clustering)\n",
    "8. [Get cluster statistics such as : \"pattern\", \"mean_length\", \"mean_similarity\"](#cluster_stats)\n",
    "9. [Save clustered data to Ceph](#save_to_ceph)\n",
    "10. [View data from each cluster](#view_data)\n",
    " 1. [Cluster No. 0: FileNotFoundError](#c0)\n",
    " 2. [Cluster No. 1: UnableToExecuteGccError](#c1)\n",
    " 3. [Cluster No. 3: NoMatchingDistributionFoundError](#c3)\n",
    "11. [Clusters with more than one error](#clusters_with_more_than_one_error)\n",
    " 1. [Cluster No. 10: ImportError, HTTPError](#c10)\n",
    " 2. [Cluster No. 106: CalledProcessError, FileNotFoundError, KeyError, RuntimeError](#c106)\n",
    " 3. [Cluster No. 116:  ConnectionError, OSError, MaxRetryError, DistutilsError, ResponseError](#c16)\n",
    " 4. [Cluster No. 7: CheckTheLogsError : Need further exploring](#c7) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026891,
     "end_time": "2020-08-14T21:58:32.204958",
     "exception": false,
     "start_time": "2020-08-14T21:58:32.178067",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Introduction  <a id='Introduction'></a>\n",
    "\n",
    "The purpose of this notebook is to cluster solver errors so that we can derive context on why dependencies cannot be solved in order to better advise users on why something cannot be used.\n",
    "\n",
    "#### Summary :\n",
    "- Preprocessed data by [PreprocessSolverErrorData](./PreprocessSolverErrorData.ipynb) notebook is loaded.\n",
    "- Each word in converted into a vector using [Word2Vec](https://radimrehurek.com/gensim/models/word2vec.html) (Continuous Bag of Words model). \n",
    "- Each error message is then converted into a vector(Sentence2vec using word2vec model).\n",
    "- Clustering is done using [DBScan](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html).\n",
    "- Cluster statistics such as \"pattern\", \"mean_length\" and \"mean_similarity\" is calculated.\n",
    "- Error Class is defined and added to the dataframe.\n",
    "- Saved the classified error data to Ceph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027523,
     "end_time": "2020-08-14T21:58:32.259163",
     "exception": false,
     "start_time": "2020-08-14T21:58:32.231640",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import packages <a id='Import_packages'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T21:58:32.317778Z",
     "iopub.status.busy": "2020-08-14T21:58:32.317408Z",
     "iopub.status.idle": "2020-08-14T21:58:33.592851Z",
     "shell.execute_reply": "2020-08-14T21:58:33.592454Z"
    },
    "papermill": {
     "duration": 1.306723,
     "end_time": "2020-08-14T21:58:33.592963",
     "exception": false,
     "start_time": "2020-08-14T21:58:32.286240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import pickle\n",
    "import numpy as np\n",
    "import difflib\n",
    "import regex as re\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "from math import sqrt\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from gensim.models import Word2Vec\n",
    "from kneed import KneeLocator\n",
    "from string import punctuation    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T21:58:33.669070Z",
     "iopub.status.busy": "2020-08-14T21:58:33.668703Z",
     "iopub.status.idle": "2020-08-14T21:58:33.673199Z",
     "shell.execute_reply": "2020-08-14T21:58:33.672869Z"
    },
    "papermill": {
     "duration": 0.050758,
     "end_time": "2020-08-14T21:58:33.673288",
     "exception": false,
     "start_time": "2020-08-14T21:58:33.622530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 2600)\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T21:58:33.750865Z",
     "iopub.status.busy": "2020-08-14T21:58:33.750513Z",
     "iopub.status.idle": "2020-08-14T21:58:33.754694Z",
     "shell.execute_reply": "2020-08-14T21:58:33.754409Z"
    },
    "papermill": {
     "duration": 0.044047,
     "end_time": "2020-08-14T21:58:33.754777",
     "exception": false,
     "start_time": "2020-08-14T21:58:33.710730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cpu_number = multiprocessing.cpu_count()\n",
    "w2v_window= 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027656,
     "end_time": "2020-08-14T21:58:33.809108",
     "exception": false,
     "start_time": "2020-08-14T21:58:33.781452",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load the clean solver data saved by 'PreprocessSolverErrorData' notebook <a id='load_clean_data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T21:58:33.868663Z",
     "iopub.status.busy": "2020-08-14T21:58:33.868293Z",
     "iopub.status.idle": "2020-08-14T21:58:33.869907Z",
     "shell.execute_reply": "2020-08-14T21:58:33.869613Z"
    },
    "papermill": {
     "duration": 0.031899,
     "end_time": "2020-08-14T21:58:33.869987",
     "exception": false,
     "start_time": "2020-08-14T21:58:33.838088",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "preprocessed_filename = 'error-clean-data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T21:58:34.011851Z",
     "iopub.status.busy": "2020-08-14T21:58:34.011483Z",
     "iopub.status.idle": "2020-08-14T21:58:46.095309Z",
     "shell.execute_reply": "2020-08-14T21:58:46.095024Z"
    },
    "papermill": {
     "duration": 12.123651,
     "end_time": "2020-08-14T21:58:46.095383",
     "exception": false,
     "start_time": "2020-08-14T21:58:33.971732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "entire_error_df = pd.read_csv(preprocessed_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T21:58:46.160611Z",
     "iopub.status.busy": "2020-08-14T21:58:46.160129Z",
     "iopub.status.idle": "2020-08-14T21:58:46.162383Z",
     "shell.execute_reply": "2020-08-14T21:58:46.162713Z"
    },
    "papermill": {
     "duration": 0.039522,
     "end_time": "2020-08-14T21:58:46.162802",
     "exception": false,
     "start_time": "2020-08-14T21:58:46.123280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93532"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entire_error_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030672,
     "end_time": "2020-08-14T21:58:46.222727",
     "exception": false,
     "start_time": "2020-08-14T21:58:46.192055",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Filter data using Solver / datetime <a id='filter'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T21:58:46.288397Z",
     "iopub.status.busy": "2020-08-14T21:58:46.288025Z",
     "iopub.status.idle": "2020-08-14T21:58:46.289489Z",
     "shell.execute_reply": "2020-08-14T21:58:46.289788Z"
    },
    "papermill": {
     "duration": 0.0356,
     "end_time": "2020-08-14T21:58:46.289883",
     "exception": false,
     "start_time": "2020-08-14T21:58:46.254283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_data(entire_error_df, solver_name=None, start_date='2019-12-27',end_date='2020-01-14', mode='solver'):\n",
    "    if mode == 'solver':\n",
    "        error_df = entire_error_df.loc[entire_error_df['solver'] == solver_name]\n",
    "    elif mode == 'datetime':\n",
    "        mask = (entire_error_df['datetime'] >= start_date) & (entire_error_df['datetime'] <= end_date)\n",
    "        error_df = entire_error_df.loc[mask]\n",
    "    elif mode == 'all':\n",
    "        error_df = entire_error_df\n",
    "    return error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T21:58:46.375631Z",
     "iopub.status.busy": "2020-08-14T21:58:46.375133Z",
     "iopub.status.idle": "2020-08-14T21:58:46.381674Z",
     "shell.execute_reply": "2020-08-14T21:58:46.377708Z"
    },
    "papermill": {
     "duration": 0.049179,
     "end_time": "2020-08-14T21:58:46.381794",
     "exception": false,
     "start_time": "2020-08-14T21:58:46.332615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['solver-fedora-31-py37', 'solver-fedora-31-py38',\n",
       "       'solver-fedora-32-py37', 'solver-fedora-32-py38',\n",
       "       'solver-rhel-8-py36'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entire_error_df['solver'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T21:58:46.478180Z",
     "iopub.status.busy": "2020-08-14T21:58:46.473947Z",
     "iopub.status.idle": "2020-08-14T21:58:46.479449Z",
     "shell.execute_reply": "2020-08-14T21:58:46.479748Z"
    },
    "papermill": {
     "duration": 0.060463,
     "end_time": "2020-08-14T21:58:46.479862",
     "exception": false,
     "start_time": "2020-08-14T21:58:46.419399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#error_df = filter_data(entire_error_df, solver_name = 'solver-fedora-31-py37', mode='solver')\n",
    "#error_df = filter_data(entire_error_df, start_date='2019-12-24',end_date='2020-01-14', mode='datetime')\n",
    "error_df = filter_data(entire_error_df, mode = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T21:58:46.576355Z",
     "iopub.status.busy": "2020-08-14T21:58:46.575981Z",
     "iopub.status.idle": "2020-08-14T21:58:46.581207Z",
     "shell.execute_reply": "2020-08-14T21:58:46.581485Z"
    },
    "papermill": {
     "duration": 0.059684,
     "end_time": "2020-08-14T21:58:46.581628",
     "exception": false,
     "start_time": "2020-08-14T21:58:46.521944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93532"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(error_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.043791,
     "end_time": "2020-08-14T21:58:46.666852",
     "exception": false,
     "start_time": "2020-08-14T21:58:46.623061",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Extract tokenized_clustering_data for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T21:58:46.748929Z",
     "iopub.status.busy": "2020-08-14T21:58:46.748605Z",
     "iopub.status.idle": "2020-08-14T21:58:46.753976Z",
     "shell.execute_reply": "2020-08-14T21:58:46.753674Z"
    },
    "papermill": {
     "duration": 0.050416,
     "end_time": "2020-08-14T21:58:46.754057",
     "exception": false,
     "start_time": "2020-08-14T21:58:46.703641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_clustering_data = error_df['tokenized_clustering_data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.062159,
     "end_time": "2020-08-14T21:58:46.876621",
     "exception": false,
     "start_time": "2020-08-14T21:58:46.814462",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Word to Vector Conversion using Continuous Bag of Words model (CBOW) <a id='word2vec'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T21:58:46.953459Z",
     "iopub.status.busy": "2020-08-14T21:58:46.953055Z",
     "iopub.status.idle": "2020-08-14T21:58:46.954985Z",
     "shell.execute_reply": "2020-08-14T21:58:46.955250Z"
    },
    "papermill": {
     "duration": 0.040824,
     "end_time": "2020-08-14T21:58:46.955343",
     "exception": false,
     "start_time": "2020-08-14T21:58:46.914519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in training data : 93532\n"
     ]
    }
   ],
   "source": [
    "print('Number of rows in training data :', len(clean_clustering_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T21:58:47.126227Z",
     "iopub.status.busy": "2020-08-14T21:58:47.083675Z",
     "iopub.status.idle": "2020-08-14T21:58:47.127601Z",
     "shell.execute_reply": "2020-08-14T21:58:47.127886Z"
    },
    "papermill": {
     "duration": 0.132731,
     "end_time": "2020-08-14T21:58:47.127978",
     "exception": false,
     "start_time": "2020-08-14T21:58:46.995247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detect_embedding_size(tokens):\n",
    "    flat_list = [item for row in tokens for item in row]\n",
    "    vocab = set(flat_list)\n",
    "    embedding_size = round(len(vocab) ** (2/3))\n",
    "    if embedding_size >= 400:\n",
    "        embedding_size = 400\n",
    "    return embedding_size\n",
    "\n",
    "w2v_size = detect_embedding_size(clean_clustering_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T21:58:47.228044Z",
     "iopub.status.busy": "2020-08-14T21:58:47.227719Z",
     "iopub.status.idle": "2020-08-14T21:58:47.229223Z",
     "shell.execute_reply": "2020-08-14T21:58:47.228926Z"
    },
    "papermill": {
     "duration": 0.060265,
     "end_time": "2020-08-14T21:58:47.229305",
     "exception": false,
     "start_time": "2020-08-14T21:58:47.169040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokens_vectorization(clustering_data, w2v_size, w2v_window, cpu_number, model_name):\n",
    "    iterations = 100\n",
    "    word2vec = Word2Vec(clustering_data,\n",
    "                           size = w2v_size, \n",
    "                           window = w2v_window, \n",
    "                           min_count=1, \n",
    "                           workers = cpu_number,\n",
    "                           iter=iterations)\n",
    "    word2vec.save(model_name)\n",
    "    return word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T21:58:47.359940Z",
     "iopub.status.busy": "2020-08-14T21:58:47.324416Z",
     "iopub.status.idle": "2020-08-14T21:59:41.412438Z",
     "shell.execute_reply": "2020-08-14T21:59:41.412093Z"
    },
    "papermill": {
     "duration": 54.153255,
     "end_time": "2020-08-14T21:59:41.412534",
     "exception": false,
     "start_time": "2020-08-14T21:58:47.259279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "word2vec = tokens_vectorization(clean_clustering_data, \n",
    "                                 w2v_size = w2v_size, \n",
    "                                 w2v_window= w2v_window, \n",
    "                                 cpu_number = cpu_number, \n",
    "                                 model_name='../models/word2vec.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.031534,
     "end_time": "2020-08-14T21:59:41.474685",
     "exception": false,
     "start_time": "2020-08-14T21:59:41.443151",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Sentence (error message) to vector conversion <a id='sent2vec'></a>\n",
    "\n",
    "sum all content words in the documents and divide by the number of content words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T21:59:41.557039Z",
     "iopub.status.busy": "2020-08-14T21:59:41.556650Z",
     "iopub.status.idle": "2020-08-14T21:59:41.558497Z",
     "shell.execute_reply": "2020-08-14T21:59:41.558128Z"
    },
    "papermill": {
     "duration": 0.045552,
     "end_time": "2020-08-14T21:59:41.558589",
     "exception": false,
     "start_time": "2020-08-14T21:59:41.513037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sentence_vectorization(clustering_data, word2vec):\n",
    "    sent2vec = []\n",
    "    for sent in clustering_data:\n",
    "        sent_vec = []\n",
    "        numw = 0\n",
    "        for w in sent:\n",
    "            try:\n",
    "                sent_vec = word2vec[w] if numw == 0 else np.add(sent_vec, word2vec[w])\n",
    "                numw += 1\n",
    "            except Exception:\n",
    "                pass\n",
    "        sent2vec.append(np.asarray(sent_vec) / numw)   \n",
    "    return np.vstack(sent2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T21:59:41.629904Z",
     "iopub.status.busy": "2020-08-14T21:59:41.629465Z",
     "iopub.status.idle": "2020-08-14T21:59:53.695876Z",
     "shell.execute_reply": "2020-08-14T21:59:53.695567Z"
    },
    "papermill": {
     "duration": 12.103375,
     "end_time": "2020-08-14T21:59:53.695961",
     "exception": false,
     "start_time": "2020-08-14T21:59:41.592586",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skotak/.local/share/virtualenvs/solver-errors-reporter-IXJVQ0hE/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "sent2vec = sentence_vectorization(clean_clustering_data, word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029754,
     "end_time": "2020-08-14T21:59:53.753411",
     "exception": false,
     "start_time": "2020-08-14T21:59:53.723657",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Clustering using DBScan  <a id='clustering'></a>\n",
    "\n",
    "Based on a set of points DBSCAN groups together points that are close to each other based on a distance measurement(epsilon) and a minimum number of points. It also marks as outliers the points that are in low-density regions.\n",
    "\n",
    "Find the avg_distances using NearestNeighbors between the data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T21:59:53.822273Z",
     "iopub.status.busy": "2020-08-14T21:59:53.821916Z",
     "iopub.status.idle": "2020-08-14T22:00:49.473752Z",
     "shell.execute_reply": "2020-08-14T22:00:49.474052Z"
    },
    "papermill": {
     "duration": 55.690177,
     "end_time": "2020-08-14T22:00:49.474150",
     "exception": false,
     "start_time": "2020-08-14T21:59:53.783973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kneighbors(sent2vec):\n",
    "    k = round(sqrt(len(sent2vec)))\n",
    "    neigh = NearestNeighbors(n_neighbors=k)\n",
    "    nbrs = neigh.fit(sent2vec)\n",
    "    distances, indices = nbrs.kneighbors(sent2vec)\n",
    "    distances = [np.mean(d) for d in np.sort(distances, axis=0)]\n",
    "    return distances\n",
    "\n",
    "avg_distances = kneighbors(sent2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.040285,
     "end_time": "2020-08-14T22:00:49.548751",
     "exception": false,
     "start_time": "2020-08-14T22:00:49.508466",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Calculate epsilon, which is the linkage distance threshold above which, clusters will not be merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T22:00:49.646866Z",
     "iopub.status.busy": "2020-08-14T22:00:49.646495Z",
     "iopub.status.idle": "2020-08-14T22:00:49.652073Z",
     "shell.execute_reply": "2020-08-14T22:00:49.651683Z"
    },
    "papermill": {
     "duration": 0.059276,
     "end_time": "2020-08-14T22:00:49.652188",
     "exception": false,
     "start_time": "2020-08-14T22:00:49.592912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def epsilon_search(distances):\n",
    "    kneedle = KneeLocator(distances, list(range(len(distances))))\n",
    "    epsilon = max(kneedle.all_elbows) if (len(kneedle.all_elbows) > 0) else 1\n",
    "    return epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T22:00:49.782833Z",
     "iopub.status.busy": "2020-08-14T22:00:49.782421Z",
     "iopub.status.idle": "2020-08-14T22:00:58.436735Z",
     "shell.execute_reply": "2020-08-14T22:00:58.437173Z"
    },
    "papermill": {
     "duration": 8.73448,
     "end_time": "2020-08-14T22:00:58.437308",
     "exception": false,
     "start_time": "2020-08-14T22:00:49.702828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epsilon = epsilon_search(avg_distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.041944,
     "end_time": "2020-08-14T22:00:58.521345",
     "exception": false,
     "start_time": "2020-08-14T22:00:58.479401",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "DBScan Clustering using epsilon and min_samples as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T22:00:58.620822Z",
     "iopub.status.busy": "2020-08-14T22:00:58.620423Z",
     "iopub.status.idle": "2020-08-14T22:00:58.621838Z",
     "shell.execute_reply": "2020-08-14T22:00:58.621495Z"
    },
    "papermill": {
     "duration": 0.054977,
     "end_time": "2020-08-14T22:00:58.621913",
     "exception": false,
     "start_time": "2020-08-14T22:00:58.566936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dbscan(epsilon, min_samples, cpu_number, sent2vec):\n",
    "    cluster_labels = DBSCAN(eps=epsilon,\n",
    "                            min_samples= min_samples,\n",
    "                            n_jobs=cpu_number).fit_predict(sent2vec)\n",
    "    return cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T21:51:03.482109Z",
     "iopub.status.busy": "2020-08-14T21:51:03.481746Z",
     "iopub.status.idle": "2020-08-14T21:51:15.113120Z",
     "shell.execute_reply": "2020-08-14T21:51:15.112730Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2020-08-14T22:00:58.663843",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#cluster_labels = hierarchical(epsilon, sent2vec)\n",
    "cluster_labels = dbscan(epsilon, 1, cpu_number, sent2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T21:51:15.183208Z",
     "iopub.status.busy": "2020-08-14T21:51:15.182799Z",
     "iopub.status.idle": "2020-08-14T21:51:15.184670Z",
     "shell.execute_reply": "2020-08-14T21:51:15.184973Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T21:51:15.263715Z",
     "iopub.status.busy": "2020-08-14T21:51:15.263282Z",
     "iopub.status.idle": "2020-08-14T21:51:15.265031Z",
     "shell.execute_reply": "2020-08-14T21:51:15.264662Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "error_df['cluster_no.'] = cluster_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Get cluster statistics such as : \"pattern\", \"mean_length\", \"mean_similarity\" <a id='cluster_stats'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T21:51:15.432395Z",
     "iopub.status.busy": "2020-08-14T21:51:15.431977Z",
     "iopub.status.idle": "2020-08-14T21:51:15.433284Z",
     "shell.execute_reply": "2020-08-14T21:51:15.433586Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clustered_output(error_df, mode='INDEX'):\n",
    "    groups, unique_rows = {}, {}\n",
    "    for key, value in error_df.groupby(['cluster_no.']):\n",
    "        unique_rows[str(key)] = set(value['clustering_data'])\n",
    "        if mode == 'ALL':\n",
    "            groups[str(key)] = value.to_dict(orient='records')\n",
    "        elif mode == 'Tokenized':\n",
    "            groups[str(key)] = value['tokenized_clustering_data'].values.tolist()\n",
    "        elif mode == 'CLEANED':\n",
    "            groups[str(key)] = value['clustering_data'].values.tolist()\n",
    "    return groups, unique_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T21:51:15.557732Z",
     "iopub.status.busy": "2020-08-14T21:51:15.543368Z",
     "iopub.status.idle": "2020-08-14T21:51:15.559611Z",
     "shell.execute_reply": "2020-08-14T21:51:15.559220Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "table = str.maketrans(punctuation, ' '*len(punctuation))\n",
    "\n",
    "def find_matching_blocks(strings):\n",
    "    curr = strings[0]\n",
    "    curr = curr.replace('ERROR', '')\n",
    "    curr = curr.replace('Command exited with non-zero status code (1):', '')\n",
    "    if len(strings) == 1:\n",
    "        #return curr\n",
    "        return curr.translate(table).strip()\n",
    "    else:\n",
    "        cnt = 1\n",
    "        for i in range(cnt, len(strings)):\n",
    "            matches = difflib.SequenceMatcher(None, curr, strings[i])\n",
    "            common = []\n",
    "            for match in matches.get_matching_blocks():\n",
    "                common.append(curr[match.a:match.a + match.size])\n",
    "            curr = ''.join(common)\n",
    "            cnt = cnt + 1\n",
    "            if cnt == len(strings):\n",
    "                break\n",
    "        if curr == '':\n",
    "            'NO COMMON PATTERNS HAVE BEEN FOUND'\n",
    "        #return curr\n",
    "        return curr.translate(table).strip()\n",
    "\n",
    "def get_similarity(rows):\n",
    "    s = []\n",
    "    for i in range(0, len(rows)):\n",
    "        s.append(difflib.SequenceMatcher(None, rows[0], rows[i]).ratio() * 100)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T21:51:15.625484Z",
     "iopub.status.busy": "2020-08-14T21:51:15.625046Z",
     "iopub.status.idle": "2020-08-14T21:51:15.627007Z",
     "shell.execute_reply": "2020-08-14T21:51:15.626699Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "STATISTICS = [\"cluster_name\", \"cluster_size\", \"pattern\", 'CLASS', \"mean_similarity\"]\n",
    "\n",
    "def statistics(error_df, output_mode='frame'):\n",
    "    \"\"\"\n",
    "    Returns dictionary with statistic for all clusters\n",
    "    \"cluster_name\" - name of a cluster\n",
    "    \"cluster_size\" = number of log messages in cluster\n",
    "    \"pattern\" - all common substrings in messages in the cluster\n",
    "    \"mean_length\" - average length of log messages in cluster\n",
    "    \"mean_similarity\" - average similarity of log messages in cluster\n",
    "    (calculated as the levenshtein distances between the 1st and all other log messages)\n",
    "    :param clustered_df:\n",
    "    :param output_mode: frame | dict\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    clusters = []\n",
    "    clustered_df, unique_rows = clustered_output(error_df, mode='CLEANED')\n",
    "    clustered_df_class, unique_rows = clustered_output(error_df, mode='Tokenized')\n",
    "    for item in clustered_df:\n",
    "        row = clustered_df[item]\n",
    "        matcher = find_matching_blocks(row)\n",
    "        class_matcher = find_matching_blocks(clustered_df_class[item])\n",
    "        similarity = get_similarity(row)\n",
    "        clusters.append([item,\n",
    "                         len(row),\n",
    "                         matcher,\n",
    "                         class_matcher,\n",
    "                         #unique_rows[item],\n",
    "                         #np.mean(lengths),\n",
    "                         np.mean(similarity)])\n",
    "    df = pd.DataFrame(clusters, columns=STATISTICS).round(2).sort_values(by='cluster_size', ascending=False)\n",
    "    if output_mode == 'frame':\n",
    "        return df\n",
    "    else:\n",
    "        return df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T21:51:15.691362Z",
     "iopub.status.busy": "2020-08-14T21:51:15.690929Z",
     "iopub.status.idle": "2020-08-14T21:51:28.933182Z",
     "shell.execute_reply": "2020-08-14T21:51:28.932830Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "stat = statistics(error_df, output_mode='frame')\n",
    "stat_df = pd.DataFrame.from_dict(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T21:51:29.015663Z",
     "iopub.status.busy": "2020-08-14T21:51:29.015277Z",
     "iopub.status.idle": "2020-08-14T21:51:29.016730Z",
     "shell.execute_reply": "2020-08-14T21:51:29.017021Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Number of clusters : ', len(stat_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Generate CLASS label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T21:51:29.170458Z",
     "iopub.status.busy": "2020-08-14T21:51:29.170092Z",
     "iopub.status.idle": "2020-08-14T21:51:29.172332Z",
     "shell.execute_reply": "2020-08-14T21:51:29.171802Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_class_label(stat_df):\n",
    "    class_labels = []\n",
    "    number_of_errors = []\n",
    "    MachineDefinedError = []\n",
    "    for item in stat_df['CLASS']:\n",
    "        if \"Error\" in item.split():\n",
    "            item = item.replace('Error', '')\n",
    "        row = item.split()\n",
    "        #if len(row) > 1 and len(re.findall(r'Error', str(row))) < 2:\n",
    "        if not re.search('(\\w\\w*Error)', item):\n",
    "            MachineDefinedError.append('NO')\n",
    "            item = ''\n",
    "            for word in row:\n",
    "                item += word[0].upper() + word[1:]\n",
    "            item += \"Error\"\n",
    "        else:\n",
    "            if len(re.findall(r'Error', str(row))) > 1:\n",
    "                item = ', '.join(row)\n",
    "            else:\n",
    "                item = ''.join(row)\n",
    "            MachineDefinedError.append('YES')\n",
    "        class_labels.append(item)\n",
    "        number_of_errors.append(len(re.findall(r'Error', str(item))))\n",
    "    return class_labels, number_of_errors, MachineDefinedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T21:51:29.295213Z",
     "iopub.status.busy": "2020-08-14T21:51:29.294667Z",
     "iopub.status.idle": "2020-08-14T21:51:29.301184Z",
     "shell.execute_reply": "2020-08-14T21:51:29.300865Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_labels, number_of_errors, MachineDefinedError = get_class_label(stat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T21:51:29.422687Z",
     "iopub.status.busy": "2020-08-14T21:51:29.422092Z",
     "iopub.status.idle": "2020-08-14T21:51:29.423585Z",
     "shell.execute_reply": "2020-08-14T21:51:29.423281Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stat_df['number_of_errors'] = number_of_errors\n",
    "stat_df['MachineDefinedError?'] = MachineDefinedError\n",
    "stat_df['CLASS'] = class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T21:51:29.494448Z",
     "iopub.status.busy": "2020-08-14T21:51:29.494037Z",
     "iopub.status.idle": "2020-08-14T21:51:29.542078Z",
     "shell.execute_reply": "2020-08-14T21:51:29.541774Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "stat_df.sort_values(by='cluster_size', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T21:51:29.645667Z",
     "iopub.status.busy": "2020-08-14T21:51:29.645255Z",
     "iopub.status.idle": "2020-08-14T21:51:29.668079Z",
     "shell.execute_reply": "2020-08-14T21:51:29.667722Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "error_df['CLASS'] = error_df['cluster_no.'].map(stat_df['CLASS'])\n",
    "error_df['number_of_errors'] = error_df['cluster_no.'].map(stat_df['number_of_errors'])\n",
    "error_df['MachineDefinedError?'] = error_df['cluster_no.'].map(stat_df['MachineDefinedError?'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Save clustered data to Ceph <a id='save_to_ceph'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T21:51:29.898971Z",
     "iopub.status.busy": "2020-08-14T21:51:29.898604Z",
     "iopub.status.idle": "2020-08-14T21:51:29.900105Z",
     "shell.execute_reply": "2020-08-14T21:51:29.900389Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['THOTH_S3_ENDPOINT_URL'] = 'https://s3.upshift.redhat.com/'\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = AWS_ACCESS_KEY_ID\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = AWS_SECRET_ACCESS_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T21:51:29.970295Z",
     "iopub.status.busy": "2020-08-14T21:51:29.969872Z",
     "iopub.status.idle": "2020-08-14T21:51:29.971256Z",
     "shell.execute_reply": "2020-08-14T21:51:29.971515Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "def store_csv_to_ceph(error_df):\n",
    "    csv_buffer = StringIO()\n",
    "    error_df = error_df.drop(columns =['index', 'message','split_message', 'Error_info', 'command_info', \n",
    "                                       'cwd', 'Complete_output','ERROR', 'Exception', 'specific_error'])\n",
    "    error_df.to_csv(csv_buffer, header=False, sep ='`', index=False)\n",
    "    bucket = 'DH-PLAYPEN'\n",
    "    s3_resource = boto3.resource('s3',\n",
    "                        endpoint_url= os.environ['THOTH_S3_ENDPOINT_URL'],\n",
    "                        aws_access_key_id = os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
    "                        aws_secret_access_key= os.environ['AWS_SECRET_ACCESS_KEY'])\n",
    "    s3_resource.Object(bucket, 'thoth/data/solver-error-context/solver-error-context.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-14T21:51:30.040790Z",
     "iopub.status.busy": "2020-08-14T21:51:30.039950Z",
     "iopub.status.idle": "2020-08-14T21:51:33.170825Z",
     "shell.execute_reply": "2020-08-14T21:51:33.170077Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "store_csv_to_ceph(error_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## View data from each cluster <a id='view_data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data_from_cluster(df_processed, clusters, cluster_number):\n",
    "    indices = [i for i, x in enumerate(clusters) if x == cluster_number]\n",
    "    df_grouped = df_processed.iloc[indices]\n",
    "    print(len(df_grouped))\n",
    "    return df_grouped\n",
    "\n",
    "def split_log(log_messages):\n",
    "    log_messages = log_messages.split('\\n')\n",
    "    return log_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Cluster No. 0: FileNotFoundError <a id='c0'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_data_from_cluster(error_df, cluster_labels, 0)[['package_name', 'package_version', 'solver','message', \n",
    "                                                    'specific_error', 'CLASS', 'MachineDefinedError?']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Cluster No. 1: UnableToExecuteGccError\t<a id='c1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_data_from_cluster(error_df, cluster_labels, 1)[['package_name', 'package_version', 'solver','message', \n",
    "                                                    'specific_error', 'CLASS', 'MachineDefinedError?']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Cluster No. 3: NoMatchingDistributionFoundError <a id='c3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_data_from_cluster(error_df, cluster_labels, 3)[['package_name', 'package_version', 'solver','message', \n",
    "                                                    'ERROR', 'CLASS', 'MachineDefinedError?']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Clusters with more than one error  <a id='clusters_with_more_than_one_error'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Cluster No. 10: ImportError, HTTPError <a id='c10'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_data_from_cluster(error_df, cluster_labels, 10)[['package_name', 'package_version', 'solver','message', \n",
    "                                                    'specific_error', 'CLASS', 'MachineDefinedError?']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### An example of log from cluster 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_log(error_df['message'][33])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Cluster No. 106: CalledProcessError, FileNotFoundError, KeyError, RuntimeError <a id='c106'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_data_from_cluster(error_df, cluster_labels, 106)[['package_name', 'package_version', 'solver','message', \n",
    "                                                    'specific_error', 'CLASS', 'MachineDefinedError?']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### An example of log from cluster 106"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_log(error_df['message'][31434])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Cluster No. 116:  ConnectionError, OSError, MaxRetryError, DistutilsError, ResponseError <a id='c116'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_data_from_cluster(error_df, cluster_labels, 116)[['package_name', 'package_version', 'solver','message', \n",
    "                                                    'specific_error', 'CLASS', 'MachineDefinedError?']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### An example of log from cluster 116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_log(error_df['message'][71802])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Cluster No. 7: CheckTheLogsError : Need further exploring <a id='c7'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_data_from_cluster(error_df, cluster_labels, 7)[['package_name', 'package_version', 'solver','message', \n",
    "                                                    'ERROR', 'CLASS', 'MachineDefinedError?']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_log(error_df['message'][18])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "##### Missing gcc  (this is very important here to know)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "papermill": {
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "ClusterErrors.ipynb",
   "output_path": "ClusterErrors.ipynb",
   "parameters": {
    "AWS_ACCESS_KEY_ID": "JYQMDA4BM9XIGQ99YABN",
    "AWS_SECRET_ACCESS_KEY": "BtCyTbs0BGgJAAS87h25Y6vrINRivRGU7NZTvqGU",
    "preprocessed_filename": "error-clean-data.csv"
   },
   "start_time": "2020-08-14T21:58:31.088794",
   "version": "2.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
